#crawler config
[main]
#allow threads number
#if [pool reporter] always report that the pool size equals this value, please increate it
allow_crawler_thread = 3

#how many url to cache, prevent url multi-cache
preLoadUrlSize=500000

#allow inner same detect
allow_inner_same_detect = 1

#use memory to detect similar
similar_detect_in_mem = 0

#same-finder index in mem
similar_detect_index_in_mem = 0

#same detect days
similar_detect_days_interval = 30

#same detect days
similar_detect_debug_days_interval = 0

#similar detect allow
similar_detect_only_cn = 1


#snapshot 

#rewrite url
rewriteUrlPrefix = http://www.qianlima.com/downloads/agent.jsp?req=

#for configEditor
baseMbOpsUrl = http://adm.qianlima.com:8080/httpget/mbOps/zb/

#dropFlag
DropFlag = [htmlExtr_refect_flag_Pleaze_drob_zer_Dayta_]

#config sleep-interval
entrance_debug_interval_min = 1000
entrance_debug_interval_max = 1000
second_debug_interval_min = 500
second_debug_interval_max = 500

entrance_interval_min = 1000
entrance_interval_max = 10000
second_interval_min = 1000
second_interval_max = 30000


#rds operations

rds_insert_snapshot = raw::insert into crawler_snapshot(url, httpcode, html)values(?,?,?)
rds_get_url_cache = raw::select fromurl from bidding_raw order by id desc limit 100000
rds_url_check = raw::select id from bidding_raw where fromurl=?
rds_load_config = raw::select potName,ruleSetname1,rulesetname2,configdatas,rulesetvalue1,rulesetvalue2,state, updatetime from crawlconfig where id = ?
rds_collect_all_config_id = raw::select id from crawlconfig where state = 0 or state = 1
rds_load_raw_datas_to_sf = raw::select title, content, ae_template, seq from bidding_raw where id > ? and seq < ? limit 5000
rds_get_inner34_define = raw::select allow34,usetitlefor50 from crawler_single_cfg_sim_check where cid = ?
rds_load_forbidding_second_url = raw::select url from forbidding_second_url


